import os
import json
import numpy as np

class SmartConnectionsReader:
    """
    Reads and processes the data generated by the Smart Connections plugin
    from the .smart-env directory.
    """
    def __init__(self, vault_path):
        self.vault_path = vault_path
        self.smart_env_path = os.path.join(vault_path, '.smart-env', 'multi')
        self.notes = {}
        self.blocks = {}

    def _cosine_similarity(self, vec1, vec2):
        """Calculates the cosine similarity between two vectors."""
        if not isinstance(vec1, np.ndarray): vec1 = np.array(vec1)
        if not isinstance(vec2, np.ndarray): vec2 = np.array(vec2)
        
        dot_product = np.dot(vec1, vec2)
        norm_vec1 = np.linalg.norm(vec1)
        norm_vec2 = np.linalg.norm(vec2)
        
        if norm_vec1 == 0 or norm_vec2 == 0:
            return 0.0
        return dot_product / (norm_vec1 * norm_vec2)

    def load_data(self):
        """Loads and parses all .ajson files to build an in-memory database."""
        print(f"Reading from: {self.smart_env_path}")
        if not os.path.exists(self.smart_env_path):
            raise FileNotFoundError(f"Smart Connections data path not found: {self.smart_env_path}")

        for filename in os.listdir(self.smart_env_path):
            if filename.endswith('.ajson'):
                filepath = os.path.join(self.smart_env_path, filename)
                with open(filepath, 'r', encoding='utf-8') as f:
                    final_data_map = {}
                    for line in f:
                        if line.strip():
                            try:
                                # Each line is a single-entry JSON object with a trailing comma
                                line_json = json.loads("{" + line.strip().rstrip(',') + "}")
                                final_data_map.update(line_json)
                            except json.JSONDecodeError:
                                print(f"Warning: Could not parse line in {filename}: {line}")
                                continue
                    
                    for key, data in final_data_map.items():
                        if not data or not data.get('key'):
                            continue

                        item_key = data['key']
                        embedding = data.get('embeddings', {}).get('TaylorAI/bge-micro-v2', {}).get('vec')
                        if not embedding:
                           embedding = next((v.get('vec') for k, v in data.get('embeddings', {}).items() if v.get('vec')), None)


                        if 'smart_sources' in key:
                            self.notes[item_key] = {
                                'path': data.get('path', item_key),
                                'vec': np.array(embedding) if embedding else None
                            }
                        elif 'smart_blocks' in key:
                            self.blocks[item_key] = {
                                'path': data.get('path', item_key),
                                'vec': np.array(embedding) if embedding else None
                            }
        
        print(f"Loaded {len(self.notes)} notes and {len(self.blocks)} blocks with embeddings.")

    def get_note_by_path(self, path):
        """Retrieves a note by its file path."""
        return self.notes.get(path)

    def read_note_content(self, relative_path):
        """Reads the content of a note file."""
        full_path = os.path.join(self.vault_path, relative_path)
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            print(f"Warning: Note file not found at {full_path}")
            return ""

    def find_similar_notes(self, target_path, n=5, include_blocks=False):
        """Finds the most similar notes or blocks to a target note."""
        target_note = self.get_note_by_path(target_path)
        if not target_note or target_note['vec'] is None:
            print(f"Error: Target note '{target_path}' not found or has no embedding.")
            return []

        search_space = self.notes
        if include_blocks:
            search_space = {**self.notes, **self.blocks}

        similarities = []
        target_vec_dim = target_note['vec'].shape[0]

        for path, item_data in search_space.items():
            if path == target_path or item_data['vec'] is None:
                continue
            
            # Skip if embedding dimensions don't match
            if item_data['vec'].shape[0] != target_vec_dim:
                continue
            
            similarity = self._cosine_similarity(target_note['vec'], item_data['vec'])
            similarities.append({'path': path, 'score': similarity})
        
        # Sort by score in descending order and take the top N
        similarities.sort(key=lambda x: x['score'], reverse=True)
        return similarities[:n]